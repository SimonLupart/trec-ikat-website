{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction to TREC Interactive Knowledge Assistance Track","text":"<p>Voice-based assistant interactions are now widespread, with a recent Comscore report showing that over 20% of homes in America own a smart speaker. Furthermore, the recent announcement of assistant-enabled smart glasses from leading tech companies continues this trend towards real-world interaction. However, despite current assistants' ability to perform well-defined simple actions, their ability to support information seeking in conversations continues to be limited.</p> <p>Conversational Information Seeking (CIS) is an established and important research direction. It is of interest to the broad research community within information retrieval, such as ranking, summarizing and question answering (QA), as well as for natural language processing and dialogue systems communities.</p> <p>The TREC Interactive Knowledge Assistance Track (iKAT) builds on the experience of four successful years of TREC Conversational Assistance Track (CAsT), where the key focus of iKAT is on researching and developing collaborative information seeking conversational agents which can tailor and personalize their response based on what they learn about and from the user.</p> <p>The fourth year of CAsT aimed to add more conversational elements to the interaction streams, by introducing mixed initiatives (clarifications, and suggestions) to create multi-path, multi-turn conversations for each topic. TREC iKAT evolves CAsT into a new track to signal this new trajectory. iKAT aims to focus on supporting multi-path, multi-turn, multi-perspective conversations, i.e., for a given topic, the direction and the conversation that evolves depends not only on the prior responses but also on the user (and their background/perspective/context/etc). As different personas undertake various topics, systems need to build and develop a picture of who the user is, in order to best address their information needs. Put another way, iKAT focuses on system understanding of user knowledge and information needs in accordance to the available context.</p> <p>Shield: </p> <p>All data associated with this work is licensed and released under a Creative Commons Attribution-ShareAlike 4.0 International License.</p> <p></p>"},{"location":"#track-coordinators","title":"Track Coordinators","text":"<p>Mohammad Aliannejadi, University of Amsterdam, The Netherlands. Dr. Aliannejadi is an Assistant Professor at the IRLab (formerly known as ILPS), the University of Amsterdam in The Netherlands. His research is in modeling user information needs with a focus on recommender systems, unified (meta) search, and conversational systems. </p> <p>Zahra Abbasiantaeb, University of Amsterdam, The Netherlands. Zahra is a first year Ph.D. student at the the University of Amsterdam supervised by Dr. Mohammad Aliannejadi. She is working on conversational search and recommendation. Earlier, she has also worked on patent reference mining. Zahra obtained her masters in AI from the Amirkabir University of Technology with a focus on Question Answering systems.</p> <p>Shubham Chatterjee, University of Glasgow, Scotland. Dr. Chatterjee is a Research Associate in the Glasgow Representation and Information Learning (GRILL) Lab, part of the Glasgow Information Retrieval group. The goal of his research is to design intelligent search systems which would one day respond to a user's open-ended and complex information needs with a complete answer instead of a ranked list of results.</p> <p>Jeff Dalton, University of Glasgow, Scotland. Dr. Dalton is a Senior Lecturer (Associate Professor) at the Department of Computing Science, University of Glasgow. He is also the PI for the GRILL Lab. His research focuses on new methods for machine understanding of language and text data using deep neural networks and entity knowledge graphs for improving information seeking applications.</p> <p>Leif Azzopardi, University of Strathclyde, Scotland. Dr. Azzopardi is an Associate Professor in Artifical Intelligence and Data Science within the Departement of Computer and Information Sciences at the University of Strathclyde. He is the PI for the Interaction Lab (i-lab) which specializes in developing, evaluating and modelling information rich and information intensive applications and agents.</p>"},{"location":"#contact","title":"Contact","text":"<ul> <li>Twitter: @trec_ikat</li> <li>Email: trec.ikat.ai@gmail.com</li> <li>Google Groups: trec-ikat@googlegroups.com</li> <li>Slack: ikat-2023</li> </ul>"},{"location":"about/","title":"Liber pia cunctis","text":""},{"location":"about/#sola-moenia-celebratior","title":"Sola moenia celebratior","text":"<p>Lorem markdownum Iunone, condeturque pectore ostendens ambage. Inpia sub vincla quid haud pervia est unda est? Est et nepotum insisto multa quem, videtur fallitque; portis iuga, mane tuta celeri uni. Quercus non faces quondam infracto indueret, tellus, qualia: fauces vota populator mors.</p> <p>Exstinctique latus cognoscenda Mota addiderat fatetur sinus. Hic et alite prodidit siquid verbere in venit cum quodsi, processit. Violasse viventi sed quoque: agis aliae turbinis iterum inhumata est cibos, auras nunc, sub. Narrare erat credo Gangetica iuvenis vocem regere, me videri frugum, has.</p>"},{"location":"about/#vetat-in-te-pax-qua-mixta-ego","title":"Vetat in te pax qua mixta ego","text":"<p>Quod gradumque pendenti pisces cadis equitavit labor de area nisi sua. Inpia arma Phyleus, piscem sanguine et portabat parvi bicorni percusserat signa celeremque luporum inter. Locumque raptos inmemores tamen: mox lyrae, surrexere regnum contemnere optima me illinc hac erat, reliquit.</p> <ol> <li>Texit pugnacem ad subito tempus</li> <li>In erit Boeotiaque nodosque coniuge interea</li> <li>Suaque mora saepe et iamdudum quam</li> <li>Phylius illa territa inbelle saepe convertor omnes</li> </ol>"},{"location":"about/#nigrior-cornua-instantes-agricolam","title":"Nigrior cornua instantes agricolam","text":"<p>Fallunt gloria fugientem ligno iuvenalis Alcyonen infectus hederae, primasque. Radiis portant te quam illa greges vel mediamque est credere silentia; ad gerebam!</p> <p>Fulmen aperta progenies iacentem includit hanc cultique vibrata limine, obliquum copia; ex, ut. Et sine, silex ultima, tollit non, coacervatos demens zonae. Removi protinus. Pro inpediit imagine de cedunt, adhuc foret in ultra.</p> <p>Si Melicerta trunca. Quae illis motae ministros genetrice Romam delubraque erat saligno consultus Agenorides novi; cratera. Est valet, gladios, luce veri letique. Rigescere vocavit, munera mihi palmae, et moenia putat, ostendere diri Zancleia, corpore sertaque?</p>"},{"location":"data/","title":"Data","text":""},{"location":"data/#coming-soon","title":"COMING SOON","text":""},{"location":"guidelines/","title":"Guidelines","text":""},{"location":"guidelines/#coming-soon","title":"COMING SOON","text":""},{"location":"licence/","title":"Licence","text":"<p>MIT License</p> <p>Copyright (c) 2023 Shubham Chatterjee</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"}]}